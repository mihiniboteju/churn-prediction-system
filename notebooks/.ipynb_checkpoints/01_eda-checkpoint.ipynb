{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f55932",
   "metadata": {},
   "source": [
    "# üìä Customer Churn Prediction: Exploratory Data Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Business Problem:**  \n",
    "Customer churn (when customers stop doing business with a company) is a critical concern for subscription-based businesses. Acquiring new customers is 5-25x more expensive than retaining existing ones. This project aims to:\n",
    "\n",
    "1. **Understand customer behavior patterns** through data exploration\n",
    "2. **Identify key factors** that contribute to customer churn\n",
    "3. **Segment customers** into meaningful groups for targeted retention strategies\n",
    "4. **Build predictive models** to identify at-risk customers before they churn\n",
    "5. **Provide actionable insights** to reduce churn and increase revenue\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset: Telco Customer Churn\n",
    "\n",
    "**Source:** IBM Sample Data Sets  \n",
    "**Context:** Telecommunications company customer data  \n",
    "**Target Variable:** Churn (Yes/No) - Whether customer left within last month\n",
    "\n",
    "**Feature Categories:**\n",
    "- **Demographics:** Gender, SeniorCitizen, Partner, Dependents\n",
    "- **Services:** Phone, Internet, Online Security, Tech Support, etc.\n",
    "- **Account Information:** Contract type, Payment method, Tenure, Charges\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives for This Notebook\n",
    "\n",
    "1. ‚úÖ Set up the environment and load required libraries\n",
    "2. ‚úÖ Download and load the Telco Customer Churn dataset\n",
    "3. ‚úÖ Perform initial data inspection and validation\n",
    "4. ‚úÖ Understand the structure and content of each feature\n",
    "5. ‚úÖ Identify data quality issues (missing values, data types, etc.)\n",
    "6. ‚úÖ Document initial observations for deeper analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Expected Outcome:** A clean, loaded dataset ready for comprehensive exploratory data analysis in Phase 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a4d72",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Import all necessary libraries and configure display settings for optimal data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "np.random.seed(42)  # Set random seed for reproducibility\n",
    "\n",
    "# Pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 100)      # Show up to 100 rows\n",
    "pd.set_option('display.width', None)        # Auto-detect display width\n",
    "pd.set_option('display.precision', 2)       # 2 decimal places for floats\n",
    "\n",
    "# Matplotlib/Seaborn styling for professional visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')      # Clean, professional style\n",
    "sns.set_palette('husl')                      # Colorblind-friendly palette\n",
    "plt.rcParams['figure.figsize'] = (12, 6)    # Default figure size\n",
    "plt.rcParams['font.size'] = 10              # Default font size\n",
    "plt.rcParams['axes.titlesize'] = 14         # Title font size\n",
    "plt.rcParams['axes.labelsize'] = 12         # Axis label font size\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ Pandas version: {pd.__version__}\")\n",
    "print(f\"üì¶ NumPy version: {np.__version__}\")\n",
    "print(f\"üì¶ Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"üì¶ Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297c87f",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition\n",
    "\n",
    "Download the Telco Customer Churn dataset from IBM's GitHub repository and load it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset URL\n",
    "DATA_URL = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
    "\n",
    "# Define file path\n",
    "project_root = Path('/Users/mihiniboteju/churn-prediction-project')\n",
    "data_raw_path = project_root / 'data' / 'raw'\n",
    "csv_file_path = data_raw_path / 'Telco-Customer-Churn.csv'\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "data_raw_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and load data\n",
    "try:\n",
    "    print(\"üì• Downloading dataset from IBM GitHub repository...\")\n",
    "    df = pd.read_csv(DATA_URL)\n",
    "    \n",
    "    # Save to local directory for future use\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"‚úÖ Dataset downloaded and saved to: {csv_file_path}\")\n",
    "    print(f\"üìä Dataset loaded successfully into DataFrame 'df'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading dataset: {e}\")\n",
    "    print(\"\")\n",
    "    print(\"üìå Manual download instructions:\")\n",
    "    print(f\"   1. Visit: {DATA_URL}\")\n",
    "    print(f\"   2. Save the file to: {csv_file_path}\")\n",
    "    print(f\"   3. Re-run this cell\")\n",
    "    \n",
    "    # Try to load from local file if download fails\n",
    "    if csv_file_path.exists():\n",
    "        print(\"\")\n",
    "        print(\"üìÇ Found local copy, loading from file...\")\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(\"‚úÖ Dataset loaded from local file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be1b27",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection\n",
    "\n",
    "Perform a comprehensive first look at the dataset to understand its structure, size, and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1c260",
   "metadata": {},
   "source": [
    "### 3.1 Dataset Shape and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1611ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset dimensions\n",
    "rows, columns = df.shape\n",
    "\n",
    "print(\"üìè DATASET DIMENSIONS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Customers (Rows):    {rows:,}\")\n",
    "print(f\"Total Features (Columns):  {columns}\")\n",
    "print(f\"Total Data Points:         {rows * columns:,}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0357b5",
   "metadata": {},
   "source": [
    "### 3.2 First Look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 10 rows\n",
    "print(\"üëÄ FIRST 10 ROWS OF THE DATASET\")\n",
    "print(\"=\" * 50)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ba9e4",
   "metadata": {},
   "source": [
    "### 3.3 Column Names and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2eed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column information\n",
    "print(\"üìã COLUMN INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed data type breakdown\n",
    "print(\"\\nüîç DATA TYPE BREAKDOWN\")\n",
    "print(\"=\" * 50)\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "print(dtype_counts)\n",
    "print(\"\\n\")\n",
    "\n",
    "# List columns by type\n",
    "print(\"NUMERICAL COLUMNS:\")\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"  {len(numerical_cols)} columns: {numerical_cols}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"CATEGORICAL/OBJECT COLUMNS:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"  {len(categorical_cols)} columns: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd28c40",
   "metadata": {},
   "source": [
    "### 3.4 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîé MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_counts,\n",
    "    'Missing_Percentage': missing_percentages\n",
    "})\n",
    "\n",
    "# Filter to show only columns with missing values\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"‚úÖ No missing values detected in any column!\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Total missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f12902",
   "metadata": {},
   "source": [
    "### 3.5 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"üìä STATISTICAL SUMMARY - NUMERICAL FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef79f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of categorical features\n",
    "print(\"üìä STATISTICAL SUMMARY - CATEGORICAL FEATURES\")\n",
    "print(\"=\" * 50)\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d02b8d",
   "metadata": {},
   "source": [
    "### 3.6 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the target variable (Churn)\n",
    "print(\"üéØ TARGET VARIABLE ANALYSIS - CHURN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "churn_percentages = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "churn_summary = pd.DataFrame({\n",
    "    'Count': churn_counts,\n",
    "    'Percentage': churn_percentages\n",
    "})\n",
    "\n",
    "print(churn_summary)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculate churn rate\n",
    "if 'Yes' in churn_counts:\n",
    "    churn_rate = (churn_counts['Yes'] / len(df)) * 100\n",
    "    print(f\"üìà Overall Churn Rate: {churn_rate:.2f}%\")\n",
    "    print(f\"üìä This means {churn_counts['Yes']:,} out of {len(df):,} customers churned.\")\n",
    "    \n",
    "    # Class balance assessment\n",
    "    if churn_rate < 30:\n",
    "        print(\"\\n‚ö†Ô∏è  NOTE: Class imbalance detected (churn rate < 30%).\")\n",
    "        print(\"   We'll need to address this in modeling phase with:\")\n",
    "        print(\"   - class_weight='balanced' parameter\")\n",
    "        print(\"   - Focus on recall and F1-score metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e149d",
   "metadata": {},
   "source": [
    "### 3.7 Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff81c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory usage\n",
    "print(\"üíæ MEMORY USAGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "memory_usage = df.memory_usage(deep=True).sum() / 1024**2  # Convert to MB\n",
    "print(f\"Total memory used by DataFrame: {memory_usage:.2f} MB\")\n",
    "print(\"\\n\")\n",
    "print(\"Memory usage by column:\")\n",
    "mem_by_col = df.memory_usage(deep=True).sort_values(ascending=False)\n",
    "mem_by_col_mb = mem_by_col / 1024**2\n",
    "print(mem_by_col_mb.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a453c1",
   "metadata": {},
   "source": [
    "## 4. Data Dictionary\n",
    "\n",
    "Understanding each feature and its business meaning is crucial for meaningful analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Feature Categories\n",
    "\n",
    "#### **A. Customer Demographics (4 features)**\n",
    "\n",
    "| Feature | Description | Type | Values |\n",
    "|---------|-------------|------|--------|\n",
    "| **customerID** | Unique identifier for each customer | Categorical | Unique string |\n",
    "| **gender** | Customer's gender | Categorical | Male, Female |\n",
    "| **SeniorCitizen** | Whether customer is 65+ years old | Binary | 0 (No), 1 (Yes) |\n",
    "| **Partner** | Whether customer has a partner | Categorical | Yes, No |\n",
    "| **Dependents** | Whether customer has dependents | Categorical | Yes, No |\n",
    "\n",
    "---\n",
    "\n",
    "#### **B. Service Information (9 features)**\n",
    "\n",
    "| Feature | Description | Type | Values |\n",
    "|---------|-------------|------|--------|\n",
    "| **PhoneService** | Whether customer has phone service | Categorical | Yes, No |\n",
    "| **MultipleLines** | Whether customer has multiple phone lines | Categorical | Yes, No, No phone service |\n",
    "| **InternetService** | Type of internet service | Categorical | DSL, Fiber optic, No |\n",
    "| **OnlineSecurity** | Whether customer has online security add-on | Categorical | Yes, No, No internet service |\n",
    "| **OnlineBackup** | Whether customer has online backup add-on | Categorical | Yes, No, No internet service |\n",
    "| **DeviceProtection** | Whether customer has device protection add-on | Categorical | Yes, No, No internet service |\n",
    "| **TechSupport** | Whether customer has tech support add-on | Categorical | Yes, No, No internet service |\n",
    "| **StreamingTV** | Whether customer has streaming TV service | Categorical | Yes, No, No internet service |\n",
    "| **StreamingMovies** | Whether customer has streaming movies service | Categorical | Yes, No, No internet service |\n",
    "\n",
    "---\n",
    "\n",
    "#### **C. Account Information (7 features)**\n",
    "\n",
    "| Feature | Description | Type | Values/Range |\n",
    "|---------|-------------|------|-------------|\n",
    "| **tenure** | Number of months customer has stayed with company | Numerical | 0-72 months |\n",
    "| **Contract** | Type of contract | Categorical | Month-to-month, One year, Two year |\n",
    "| **PaperlessBilling** | Whether customer uses paperless billing | Categorical | Yes, No |\n",
    "| **PaymentMethod** | Customer's payment method | Categorical | Electronic check, Mailed check, Bank transfer, Credit card |\n",
    "| **MonthlyCharges** | Amount charged to customer monthly | Numerical | $18.25 - $118.75 |\n",
    "| **TotalCharges** | Total amount charged to customer | Numerical | Continuous |\n",
    "| **Churn** | **TARGET VARIABLE** - Whether customer left in last month | Categorical | Yes, No |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Target Variable: **Churn**\n",
    "\n",
    "- **Definition:** Whether the customer discontinued service in the last month\n",
    "- **Values:** \n",
    "  - `Yes` = Customer churned (left the company)\n",
    "  - `No` = Customer retained (still active)\n",
    "- **Business Importance:** This is what we're trying to predict. Identifying customers likely to churn allows proactive retention efforts.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Key Business Insights from Features:\n",
    "\n",
    "1. **Tenure** is likely a strong predictor - longer customers are typically more loyal\n",
    "2. **Contract Type** may indicate commitment level - month-to-month vs annual contracts\n",
    "3. **Service bundles** (multiple add-ons) might reduce churn\n",
    "4. **Payment method** could indicate customer engagement level\n",
    "5. **Charges** (both monthly and total) represent customer value\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ee160",
   "metadata": {},
   "source": [
    "## 5. Unique Values Inspection\n",
    "\n",
    "Examine unique values for categorical features to understand the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f667c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values for each categorical column\n",
    "print(\"üîç UNIQUE VALUES IN CATEGORICAL COLUMNS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    unique_values = df[col].unique()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique count: {unique_count}\")\n",
    "    \n",
    "    # Only show values if there are reasonable number of unique values\n",
    "    if unique_count <= 10:\n",
    "        print(f\"  Values: {unique_values}\")\n",
    "    else:\n",
    "        print(f\"  Sample values: {unique_values[:10]}... (showing first 10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e17fd",
   "metadata": {},
   "source": [
    "## 6. Data Quality Issues Identified\n",
    "\n",
    "Document any issues that need to be addressed in subsequent phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75089d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TotalCharges data type issue (common in this dataset)\n",
    "print(\"‚ö†Ô∏è  DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if TotalCharges is object type (should be numeric)\n",
    "if df['TotalCharges'].dtype == 'object':\n",
    "    print(\"\\nüî¥ ISSUE #1: TotalCharges is stored as 'object' instead of numeric\")\n",
    "    print(\"   This likely means there are non-numeric values.\")\n",
    "    \n",
    "    # Try to identify the non-numeric values\n",
    "    try:\n",
    "        non_numeric = df[pd.to_numeric(df['TotalCharges'], errors='coerce').isnull()]['TotalCharges'].unique()\n",
    "        print(f\"   Non-numeric values found: {non_numeric}\")\n",
    "        print(f\"   Count of problematic rows: {df[pd.to_numeric(df['TotalCharges'], errors='coerce').isnull()].shape[0]}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"   ‚úÖ Solution: Will convert to numeric in Phase 3 (Feature Engineering)\")\n",
    "\n",
    "# Check for duplicate customerIDs\n",
    "duplicate_ids = df['customerID'].duplicated().sum()\n",
    "if duplicate_ids > 0:\n",
    "    print(f\"\\nüî¥ ISSUE #2: Found {duplicate_ids} duplicate customer IDs\")\n",
    "    print(\"   ‚úÖ Solution: Will investigate and handle in Phase 3\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No duplicate customer IDs found\")\n",
    "\n",
    "# Check for potential outliers in numerical columns\n",
    "print(\"\\nüìä Checking for potential outliers...\")\n",
    "for col in ['tenure', 'MonthlyCharges']:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))].shape[0]\n",
    "    print(f\"   {col}: {outliers} potential outliers detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a4c69",
   "metadata": {},
   "source": [
    "## 7. Initial Observations & Next Steps\n",
    "\n",
    "### ‚úÖ What We've Accomplished:\n",
    "\n",
    "1. ‚úÖ Successfully loaded the Telco Customer Churn dataset (7,043 customers √ó 21 features)\n",
    "2. ‚úÖ Identified the target variable (Churn) and observed class distribution\n",
    "3. ‚úÖ Categorized features into demographics, services, and account information\n",
    "4. ‚úÖ Detected data quality issues (TotalCharges data type)\n",
    "5. ‚úÖ Established baseline understanding of the dataset structure\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Key Initial Findings:\n",
    "\n",
    "1. **Dataset Size:** 7,043 customers with 21 features - sufficient for meaningful ML models\n",
    "2. **Target Distribution:** Churn rate appears to be ~26% (moderate class imbalance)\n",
    "3. **Feature Mix:** Good balance of categorical (16) and numerical (3-5) features\n",
    "4. **Data Quality:** Generally clean, but TotalCharges needs type conversion\n",
    "5. **No Missing Values:** No explicit NULL values detected (but empty strings may exist)\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Next Steps (Phase 2 - Full EDA):\n",
    "\n",
    "1. **Deep Dive Analysis:**\n",
    "   - Correlation analysis between features and churn\n",
    "   - Distribution analysis of numerical features\n",
    "   - Relationship between categorical features and churn\n",
    "\n",
    "2. **Visualizations to Create:**\n",
    "   - Churn distribution (bar chart)\n",
    "   - Tenure vs Churn (histogram/KDE)\n",
    "   - Monthly Charges vs Total Charges scatter plot\n",
    "   - Contract Type vs Churn rate (grouped bar chart)\n",
    "   - Correlation heatmap\n",
    "   - Services usage patterns\n",
    "\n",
    "3. **Hypotheses to Test:**\n",
    "   - Do month-to-month customers churn more than annual contract customers?\n",
    "   - Is tenure inversely correlated with churn?\n",
    "   - Do customers with more services have lower churn rates?\n",
    "   - Does payment method affect churn?\n",
    "\n",
    "4. **Data Preparation:**\n",
    "   - Fix TotalCharges data type\n",
    "   - Identify and handle any remaining data quality issues\n",
    "   - Prepare data for feature engineering in Phase 3\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Expected Insights:\n",
    "\n",
    "By the end of Phase 2, we should be able to answer:\n",
    "- Which features are most strongly correlated with churn?\n",
    "- What are the characteristics of customers who churn vs those who stay?\n",
    "- Are there any obvious patterns or segments in the data?\n",
    "- What features should we focus on for modeling?\n",
    "\n",
    "---\n",
    "\n",
    "**Status: Phase 1 Complete ‚úÖ**  \n",
    "**Ready for: Phase 2 - Comprehensive Exploratory Data Analysis**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
